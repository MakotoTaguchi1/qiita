---
title: 生成 AI 入門してみた ③ Transformer の仕組み編
tags:
  - 初心者
  - Transformer
  - 生成AI
private: false
updated_at: '2026-01-04T11:51:14+09:00'
id: 06d29f77e35d6fdd7c4b
organization_url_name: null
slide: false
ignorePublish: false
---

## はじめに

この記事は「生成 AI 入門してみた ① 基本編」「② 自然言語処理の仕組み編」に続く、第 3 部です。
ここでは現在の LLM（大規模言語モデル）の中核となっている **Transformer** に焦点を当てます。

:::note info
この記事は生成 AI 初心者が書いており、技術的に正しくない記載・表現が全然ありえます。
また技術的な正しさよりも、初心者・非エンジニアでも理解できるような粒度を目指して書きました。こちらご留意下さい。
:::

## 目次

[第 1 部: 基礎編](https://qiita.com/MAKOTO1995/items/44da29e6d73ff8c84b6d)

キーワード

- 推論・学習
- LLM
- ニューラルネットワーク・ディープラーニング
- LLM と AI エージェントの違い

[第 2 部: 自然言語処理の仕組み編](https://qiita.com/MAKOTO1995/items/98ab394bbdf2c3890302)

キーワード

- 自然言語処理とは
- 機械翻訳との関係
- 単語の意味を理解する仕組み（ベクトル・word2vec）
- 文章を理解する仕組み（RNN・エンコーダ・デコーダ・seq2seq・Attention）

[第 3 部: Trasformer の仕組み編](https://qiita.com/MAKOTO1995/items/06d29f77e35d6fdd7c4b) **← 今ココ**

キーワード

- Transformer の理解がなぜ重要か
- seq2seq と Transformer の違い
- Transformer の構造
- Transformer の学習の仕組み

[第 4 部: 発展編](https://qiita.com/MAKOTO1995/items/e2d229b2f11ba8fadaef)

キーワード

- MoE
- RAG
- ReAct

## この章でわかること

- Transformer がなぜ生成 AI を知るために重要か
- 従来の Seq2Seq と Transformer の違い
- Transformer の全体構造と役割分担
- Transformer がどのように学習・推論しているのか

## 3-1. なぜ Transformer の理解が重要か

現在の ChatGPT・Claude・Gemini などは、細部の作りは違っても **土台が Transformer** であることは共通です。

第 2 部で見た通り、文章生成の本質はシンプルで、

```
「次に来る単語（トークン）を確率で予測する」
```

という計算です。  
Transformer はこの計算を、**Self-Attention を使って文脈全体から同時に行える**ようにした点が大きなポイントです。

結果として、

- 長い文脈でも関係性を捉えやすい
- 学習時の計算を並列化しやすい
- 大規模化と高精度化が現実的になった

という恩恵が生まれました。

この仕組みを理解すると、**LLM が得意なこと／苦手なこと**が見えてきます。

## 3-2. Seq2Seq と Transformer の違い

### Seq2Seq のおさらい

第 2 部で紹介した Seq2Seq（Sequence to Sequence）は、

- エンコーダ：入力文章を読み取り、意味を要約する
- デコーダ：その意味をもとに、文章を 1 語ずつ生成する

という構造でした。

RNN を使った Seq2Seq では、

- 単語を 1 つずつ順番に処理する
- 過去の情報を内部状態として引き継ぐ

という特徴があります。

この仕組みにより、文章という「時系列データ」を扱えるようになりました。

### RNN ベース Seq2Seq の課題

一方で、RNN ベースの Seq2Seq には次のような課題がありました。

- 文章が長くなると、前半の情報が弱くなりやすい
- 単語を順番に処理するため、計算を並列化しにくい

この問題を補うために登場したのが Attention でしたが、それでも RNN 自体の制約は残っていました。

### Transformer の決定的な違い

Transformer は、**RNN を使っていません。**
代わりに中核となるのが、**Self-Attention（自己注意機構）** です。

Transformer では、Self-Attention により、

- 単語列全体をまとめて扱い
- 単語同士の関係性を一括で計算する

ことができます。

この結果、

- 長い文章でも文脈が薄れにくい
- GPU を使った並列計算がしやすい

という、大きなメリットが生まれました。

Transformer のおかげで「**コンテキストの保持**という点で大きな恩恵を受けることができた」とも言えるかもしれません。

## 3-3. Transformer の全体構造

### エンコーダとデコーダ

Transformer は、基本的には Seq2Seq と同じく、**エンコーダ**、**デコーダ** から構成されています。

※ なお現在の GPT 系 LLM は「デコーダのみ」を使っていますが、ここでは理解しやすさのため、基本形の構造で説明します。

役割は次の通りです。

**エンコーダ**

- 入力された文章を受け取り
- 文脈や意味の特徴を数値として表現する

**デコーダ**

- エンコーダの結果と
- 直前までに生成した文章をもとに
- 次の単語の確率を出力する

### レイヤーを積み重ねた構造

Transformer のエンコーダ・デコーダ内部では、**それぞれ同じ構造の「本体ブロック（レイヤー）」を何層も重ねた形** になっています。

- 1 層だけでも文章は理解できる
- 層を重ねることで、より抽象的で高度な表現ができる

この考え方は、ニューラルネットワークのうち隠れ層を複数重ねたものである、**ディープラーニング**と言えそうです。

## 3-4. Transformer の入力処理

エンコーダ・デコーダいずれも**翻訳元文章の入力直後**に、以下 2 つの処理が走ります。

### 1. 単語を数値に変換する（埋め込み）

Transformer でも、入力された文章はまず

- トークンに分割され
- 各トークンが **埋め込み（Embedding）** によって**数値ベクトル**に変換されます

ここまでは、第 2 部で見た自然言語処理と同じです。

### 2. 単語の順番を教える（位置情報）

Attention は単語同士の関係性を見る仕組みですが、そのままでは **単語の並び順** が分かりません。

そこで Transformer では「この単語は文章の何番目か」という情報を、数値として追加します。

これを **位置付与（Positional Encoding）** と呼びます。

この工夫によって、

- 単語の意味
- 単語同士の関係
- 単語の順序

を同時に扱えるようになります。

## 3-5. Self-Attention の仕組み

Transformer の核となる仕組みが **Self-Attention** です。

### Self-Attention とは何をしているのか

Self-Attention は、**文章中の各単語が、他のどの単語と、どれくらい関係が深いか**を数値で計算する仕組みです。

例えば、

```
彼はリンゴを食べた。それはとても甘かった。
```

という文章では、

- 「それ」は
- 「リンゴ」と強く関係している

と判断されます。

Self-Attention により、こうした **距離に依存しない文脈理解** が可能になります。

### 類似度で「重要さ」を決める

Self-Attention では、

- 各単語をベクトルとして表し
- ベクトル同士の「関係の強さ（関連度）」を計算します

関係が深い単語ほど重みが大きくなり、「この単語を強く参照する」と判断されます。

この重み付けによって、文章全体の意味を柔軟に捉えられるようになります。

## 3-6. エンコーダとデコーダは、どう役割分担しているのか

ここまでで、Transformer では **Self-Attention** を中心に、

- 単語同士の関係性を捉え
- 文脈全体を踏まえて処理する

という仕組みが使われていることを見てきました。

ただし、これらは **単体の仕組みとして理解しただけ** では、
実際に Transformer が「どうやって文章を生成しているのか」は見えてきません。

ここからは「エンコーダとデコーダが、それぞれどんな情報を材料にして、どんな順番で処理しているのか」を整理します。

※ 実際 GPT 系はデコーダのみが使われていますが、ここでは機械翻訳のような **エンコーダ ＋ デコーダ型** を例に説明します。

### エンコーダ：入力文を「理解する」

まずエンコーダは、入力された文章全体を受け取ります。

エンコーダ内部では、次のような処理が行われます。

- **Self-Attention** により、単語同士の関係性を捉える
- Self-Attention の結果を受け取り、**Feed Forward** の推論によってさらに特徴を変換・抽象化する（= **文脈に合わせて単語に意味付けするイメージ**）

このブロックを**何層も重ねる**ことで、各単語は

- 単語そのものの意味
- 周囲の単語を考慮した文脈的な意味

を含んだ、より高精度な表現になっていきます。

エンコーダの最終的な出力は、次の通りです。

```
入力文章全体の意味や文脈を表す特徴の集合（= 翻訳元文章の特徴エッセンス）
```

この段階では、**まだ文章は生成していません。**
エンコーダはあくまで「入力文を理解する」役割に専念しています。

ここまでのエンコーダ部分のみを図示すると、以下のようになります。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/577028/f26092aa-72f2-4263-98e5-ba7e8fa3cd62.png)

### デコーダ：理解結果を使って「次の単語」を決める

次にデコーダの出番です。

デコーダに対しては、次の **2 つのインプットがあります**。

```
1. 直前の単語まで生成した文章
2. エンコーダが出力した「翻訳元文章の特徴エッセンス」
```

これらをもとに、**次の単語を 1 つ推論**します。

#### ① Masked Self-Attention：生成中の文脈を理解する

まずデコーダは **生成中の文（直前までに生成した単語列）** だけを対象に Self-Attention を行います。

このとき、未来の単語は見えないように **マスク** されています。

これにより、「先の答えを知った状態で文章を書く」ことを防ぎ、**人間が文章を書くのと同じ条件**で処理が行われます。

#### ② Source-Target Attention：原文と生成文を対応付ける

次にデコーダは、**エンコーダから渡された「翻訳元文章の特徴エッセンス」を参照**します。
ここで行われるのは、今生成しようとしている単語が**入力分（翻訳元文章）のどの部分と関係が深いか**を判断する処理です。

つまりデコーダは、

- 「ここまでに生成した文章」と
- 「翻訳元文章を理解した結果（＝エンコーダの出力）」

を **照らし合わせながら**、次の単語を考えています。

機械翻訳で言えば、
「今書こうとしているこの単語は、元の文章のどの部分を意識して書くべきか」を考える処理です。

このように、原文（Source）と生成中の文（Target）の間で行われる Attention は、
一般に「**Source-Target Attention**（または Cross-Attention）」と呼ばれます。

#### ③ Feed Forward：次の単語の確率を計算する

最後に、ニューラルネットワーク（**Feed Forward**）では、
Souce-Target Attention で得られた原文・生成文の依存関係から、翻訳先の次の単語を確率の形で推論します。

### デコーダの出力

デコーダの最終出力では、

- 語彙に含まれるすべての単語に対して
- 「次に来る確率」

が同時に計算されます。

LLM はこの確率分布をもとに、

- 最も確率が高い単語
- あるいは確率を考慮して選ばれた単語

を 1 つ選びます。

ここまでのデコーダ部分も含め Transformer 全体を図示すると、以下のようになります。
**この処理を 1 単語ずつ繰り返すことで、文章が少しずつ生成されていきます。**

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/577028/37e1138c-12fb-4787-971a-30637056b843.png)

## 3-7. Transformer の学習の仕組み

### 学習は「次の単語当てクイズ」が基本

LLM の事前学習は、文章そのものを使った **自己教師あり学習**（次の単語を当てる学習）が中心です。

例えば機械翻訳の場合、

- 入力：翻訳元の文章
- 正解（ラベル）：翻訳後の文章

というペアが使われます。

### 学習時のポイント

学習時には、

- 推論対象は「次の単語のみ」
- 直前までの単語は、正解として与えられる
- **次の単語をカンニングしないよう、未来の単語はマスクされる**

といった工夫がされています。
これにより、次の単語を当てる能力が効率よく鍛えられます。

### 推論フェーズとの違い

重要な点として、

- 学習フェーズ：重みを更新する
- 利用フェーズ（推論）：重みは更新しない

という違いがあります。

ChatGPT が会話中に賢くなっているように見えても、
**その場で学習しているわけではありません**。

あくまで、学習済みの Transformer を使って次の単語を計算しているという状態です。

## まとめ

この章では、Transformer の仕組みを整理しました。

- Transformer は LLM の中核となる構造
- RNN を使わず、Self-Attention を中心に設計されている
- 単語同士の関係性を一括で捉えられる
- 「次の単語を確率で選ぶ」処理を、高精度・大規模に実現している

次の第 4 部では、MoE・RAG・ReAct といった、人間が LLM をより有効活用するための **発展的な仕組み** を掘り下げようと思います。
